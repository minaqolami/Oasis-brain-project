{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.svm import LinearSVC\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GroupShuffleSplit\n","from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df=pd.read_csv(\"F:\\\\abc.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["RANDOM_STATE = 13\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fill_ses(x):\n","    ses = 0\n","    if x > 17:\n","        ses = 1.0\n","    elif (x < 17) and (x > 15):\n","        ses = 2.0\n","    elif (x < 15) and (x > 13):\n","        ses = 3.0\n","    elif (x < 13) and (x > 11):\n","        ses = 4.0\n","    else:\n","        ses = 5.0\n","    return ses\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"SES\"] = df.apply(lambda x : fill_ses(x.EDUC) if pd.isna(x.SES)   else x.SES, axis = 1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"SES\"] = df.SES.astype(int)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"MMSE\"] = df.MMSE.fillna(df[df[\"Group\"] == \"Demented\"][\"MMSE\"].median())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"Sex\"] = np.where(df[\"Sex\"] == \"M\", 1, 0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.drop([\"Hand\", \"MRI ID\"], axis = 1, inplace = True)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Handling Missing Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 11\n","df.loc[11,'Visit'] = 2\n","df.loc[12,'Visit'] = 3\n","df.iloc[10:13,:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 30\n","df.loc[30,'Visit'] = 2\n","df.loc[31,'Visit'] = 3\n","df.loc[32,'Visit'] = 4\n","df.iloc[29:33,:]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 34\n","df.loc[34,'Visit'] = 2\n","df.loc[35,'Visit'] = 3\n","df.iloc[33:36,:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 69\n","df.loc[69,'Visit'] = 2\n","df.loc[70,'Visit'] = 3\n","df.iloc[68:71]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 188\n","df.loc[188,'Visit'] = 2\n","df.iloc[187:189]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 274\n","df.loc[274,'Visit'] = 2\n","df.iloc[273:275]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_copy = df.copy()\n","df = df[df[\"Visit\"] < 3]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_visit = df[df[\"Group\"] == \"Converted\"].groupby([\"Subject ID\"]).max().reset_index()[[\"Subject ID\",\"Visit\"]]\n","for i in range(max_visit.shape[0]):\n","    target_index =  df[(df[\"Subject ID\"] == max_visit.loc[i,\"Subject ID\"]) & (df[\"Visit\"] != max_visit.loc[i,\"Visit\"]) ].index\n","    df.loc[target_index,\"Group\"] = \"Nondemented\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"Group\"] = np.where(df[\"Group\"] == \"Nondemented\", 0, 1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["split = splitter.split(df, groups=df['Subject ID'])\n","train_indexes, test_indexes = next(split)\n","train = df.iloc[train_indexes]\n","test = df.iloc[test_indexes]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train = train.drop([\"Subject ID\", \"Group\"], axis = 1)\n","y_train = train[[\"Group\"]]\n","x_test = test.drop([\"Subject ID\", \"Group\"], axis = 1)\n","y_test = test[[\"Group\"]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["delay_scaler = MinMaxScaler()\n","age_scaler = MinMaxScaler()\n","educ_scaler = MinMaxScaler()\n","mmse_scaler = MinMaxScaler()\n","etiv_scaler = MinMaxScaler()\n","\n","delay_scaler.fit(x_train[\"MR Delay\"].to_numpy().reshape(-1,1))\n","age_scaler.fit(x_train[\"Age\"].to_numpy().reshape(-1,1))\n","educ_scaler.fit(x_train[\"EDUC\"].to_numpy().reshape(-1,1))\n","mmse_scaler.fit(x_train[\"MMSE\"].to_numpy().reshape(-1,1))\n","etiv_scaler.fit(x_train[\"eTIV\"].to_numpy().reshape(-1,1))\n","\n","x_train[\"MR Delay\"] = delay_scaler.transform(x_train[\"MR Delay\"].to_numpy().reshape(-1,1))\n","x_train[\"Age\"] = age_scaler.transform(x_train[\"Age\"].to_numpy().reshape(-1,1))\n","x_train[\"EDUC\"] = educ_scaler.transform(x_train[\"EDUC\"].to_numpy().reshape(-1,1))\n","x_train[\"MMSE\"] = mmse_scaler.transform(x_train[\"MMSE\"].to_numpy().reshape(-1,1))\n","x_train[\"eTIV\"] = etiv_scaler.transform(x_train[\"eTIV\"].to_numpy().reshape(-1,1))\n","\n","x_test[\"MR Delay\"] = delay_scaler.transform(x_test[\"MR Delay\"].to_numpy().reshape(-1,1))\n","x_test[\"Age\"] = age_scaler.transform(x_test[\"Age\"].to_numpy().reshape(-1,1))\n","x_test[\"EDUC\"] = educ_scaler.transform(x_test[\"EDUC\"].to_numpy().reshape(-1,1))\n","x_test[\"MMSE\"] = mmse_scaler.transform(x_test[\"MMSE\"].to_numpy().reshape(-1,1))\n","x_test[\"eTIV\"] = etiv_scaler.transform(x_test[\"eTIV\"].to_numpy().reshape(-1,1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train=np.array(x_train,dtype=float)\n","x_test=np.array(x_test,dtype=float)\n","x_train=np.reshape(x_train,(int(x_train.shape[0]/2),2,11))\n","x_test=np.reshape(x_test,(int(x_test.shape[0]/2),2,11))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_train=np.array(y_train,dtype=float)\n","y_test=np.array(y_test,dtype=float)\n","y_train=np.reshape(y_train,(int(y_train.shape[0]/2),2,1))\n","y_test=np.reshape(y_test,(int(y_test.shape[0]/2),2,1))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_test.shape\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_lstm_rnn():\n","    lstm_rnn = tf.keras.Sequential()\n","    lstm_rnn.add(tf.keras.layers.LSTM(100, return_sequences = True,batch_input_shape = (x_train.shape[1],2,1) ) )\n","    lstm_rnn.add(tf.keras.layers.LSTM(50,return_sequences = False))\n","    lstm_rnn.add(tf.keras.layers.Dense(1,activation = \"sigmoid\"))\n","    lstm_rnn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","    return lstm_rnn\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lstm_rnn = build_lstm_rnn()\n","lstm_rnn.fit(x_train, y_train, epochs = 1)\n","not_final_lstm_rnn_prediction = lstm_rnn.predict(x_test)\n","lstm_rnn_prediction = np.where(not_final_lstm_rnn_prediction > 0.5, 1, 0)\n","print(classification_report(y_test,lstm_rnn_prediction, target_names= [\"Non-Demanted\", \"Demanted\"]))\n","lstm_rnn_conf = confusion_matrix(y_test,lstm_rnn_prediction)\n","lstm_rnn_plot_conf = ConfusionMatrixDisplay(lstm_rnn_conf)\n","lstm_rnn_plot_conf.plot()\n"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
